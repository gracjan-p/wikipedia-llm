{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[Functions](#functions)",
   "id": "fb40c28b8abd93a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### setup",
   "id": "b25d011a625f00c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:33:00.814814Z",
     "start_time": "2025-03-01T18:33:00.805998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers.commands import train\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if cuda_available else 'cpu')\n",
    "\n",
    "if cuda_available:\n",
    "    dev_count = torch.cuda.device_count()\n",
    "    dev_current = torch.cuda.current_device()\n",
    "    dev_name = torch.cuda.get_device_name(dev_current)\n",
    "    print(f'Device count: {dev_count}')\n",
    "    print(f'Current device: {dev_current}')\n",
    "    print(f'Device name: {dev_name}')"
   ],
   "id": "e3a1e5b98b8ec9bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### data",
   "id": "ddac5660f595d9d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:33:01.607804Z",
     "start_time": "2025-03-01T18:33:01.466695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import polars as pl\n",
    "\n",
    "data_path = 'D:\\\\data-science\\\\wikipedia\\\\parq\\\\train-00040-of-00041.parquet'\n",
    "\n",
    "df = pl.read_parquet(data_path)"
   ],
   "id": "c252307a0e3536d3",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:33:02.462334Z",
     "start_time": "2025-03-01T18:33:01.888856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.with_columns(\n",
    "    pl.col('text')\n",
    "    .str.replace_all(r'\\[[^]]*\\]', '')\n",
    "    .str.replace_all(r'\\([^]]*\\)', '')\n",
    "    # .str.replace_all(r'\\\"[^]]*\\\"', '')\n",
    "    # .str.replace_all(r'[\\.\\,]', '')\n",
    "    .str.replace_all(r'\\n+', ' ')\n",
    "    .str.replace_all(r' +', ' ')\n",
    ")\n",
    "\n",
    "df"
   ],
   "id": "af6e7a7fb095f3e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (157_528, 4)\n",
       "┌──────────┬───────────────────────────────┬────────────────────────┬──────────────────────────────┐\n",
       "│ id       ┆ url                           ┆ title                  ┆ text                         │\n",
       "│ ---      ┆ ---                           ┆ ---                    ┆ ---                          │\n",
       "│ str      ┆ str                           ┆ str                    ┆ str                          │\n",
       "╞══════════╪═══════════════════════════════╪════════════════════════╪══════════════════════════════╡\n",
       "│ 67963775 ┆ https://en.wikipedia.org/wiki ┆ The Angel of 8th Ave.  ┆ \"The Angel of 8th Ave\" as    │\n",
       "│          ┆ /…                            ┆                        ┆ thei…                        │\n",
       "│ 67963778 ┆ https://en.wikipedia.org/wiki ┆ Hurricane Municipal    ┆ Hurricane Municipal Airport  │\n",
       "│          ┆ /…                            ┆ Airport                ┆ al…                          │\n",
       "│ 67963783 ┆ https://en.wikipedia.org/wiki ┆ Satin berrypecker      ┆ The satin berrypecker is a   │\n",
       "│          ┆ /…                            ┆                        ┆ spe…                         │\n",
       "│ 67963841 ┆ https://en.wikipedia.org/wiki ┆ Cassinia complanata    ┆ Cassinia complanata commonly │\n",
       "│          ┆ /…                            ┆                        ┆ k…                           │\n",
       "│ 67963851 ┆ https://en.wikipedia.org/wiki ┆ Monoporella            ┆ Monoporella is a genus of    │\n",
       "│          ┆ /…                            ┆                        ┆ bryo…                        │\n",
       "│ …        ┆ …                             ┆ …                      ┆ …                            │\n",
       "│ 70201819 ┆ https://en.wikipedia.org/wiki ┆ Bianca Fernandez       ┆ Bianca Jolie Fernandez is a  │\n",
       "│          ┆ /…                            ┆                        ┆ Ca…                          │\n",
       "│ 70201882 ┆ https://en.wikipedia.org/wiki ┆ Condons and Clangibbon ┆ Condons and Clangibbon \"the  │\n",
       "│          ┆ /…                            ┆                        ┆ wh…                          │\n",
       "│ 70201886 ┆ https://en.wikipedia.org/wiki ┆ 2022 Chattanooga Red   ┆ The 2022 Chattanooga Red     │\n",
       "│          ┆ /…                            ┆ Wolves SC…             ┆ Wolve…                       │\n",
       "│ 70201947 ┆ https://en.wikipedia.org/wiki ┆ Nkiko Prosper          ┆ Turatsinze Nkiko Prosper     │\n",
       "│          ┆ /…                            ┆                        ┆ profe…                       │\n",
       "│ 70201959 ┆ https://en.wikipedia.org/wiki ┆ Michael O'Donnell      ┆ Michael A O'Donnell is an    │\n",
       "│          ┆ /…                            ┆ (Missouri po…          ┆ Amer…                        │\n",
       "└──────────┴───────────────────────────────┴────────────────────────┴──────────────────────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (157_528, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>url</th><th>title</th><th>text</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;67963775&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;The Angel of 8th Ave.&quot;</td><td>&quot;&quot;The Angel of 8th Ave&quot; as thei…</td></tr><tr><td>&quot;67963778&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;Hurricane Municipal Airport&quot;</td><td>&quot;Hurricane Municipal Airport al…</td></tr><tr><td>&quot;67963783&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;Satin berrypecker&quot;</td><td>&quot;The satin berrypecker is a spe…</td></tr><tr><td>&quot;67963841&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;Cassinia complanata&quot;</td><td>&quot;Cassinia complanata commonly k…</td></tr><tr><td>&quot;67963851&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;Monoporella&quot;</td><td>&quot;Monoporella is a genus of bryo…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;70201819&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;Bianca Fernandez&quot;</td><td>&quot;Bianca Jolie Fernandez is a Ca…</td></tr><tr><td>&quot;70201882&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;Condons and Clangibbon&quot;</td><td>&quot;Condons and Clangibbon &quot;the wh…</td></tr><tr><td>&quot;70201886&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;2022 Chattanooga Red Wolves SC…</td><td>&quot;The 2022 Chattanooga Red Wolve…</td></tr><tr><td>&quot;70201947&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;Nkiko Prosper&quot;</td><td>&quot;Turatsinze Nkiko Prosper profe…</td></tr><tr><td>&quot;70201959&quot;</td><td>&quot;https://en.wikipedia.org/wiki/…</td><td>&quot;Michael O&#x27;Donnell (Missouri po…</td><td>&quot;Michael A O&#x27;Donnell is an Amer…</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### tokens",
   "id": "856b0fff5f60f9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:33:03.645564Z",
     "start_time": "2025-03-01T18:33:03.436429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer.special_tokens_map"
   ],
   "id": "682658577897c008",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:33:27.426123Z",
     "start_time": "2025-03-01T18:33:04.462826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_tokens = df.with_columns(\n",
    "    pl.col('text').map_elements(\n",
    "        lambda x: tokenizer.encode(x, add_special_tokens=False, truncation=True, padding=False, max_length=512), return_dtype=pl.List(pl.Int64)\n",
    "    )\n",
    ")"
   ],
   "id": "703a97f61f04fa5",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:47:52.065010Z",
     "start_time": "2025-03-01T18:47:51.134236Z"
    }
   },
   "cell_type": "code",
   "source": "list_tokens = df_tokens['text'].to_list()",
   "id": "d053aa695888994a",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:47:56.264599Z",
     "start_time": "2025-03-01T18:47:56.259013Z"
    }
   },
   "cell_type": "code",
   "source": "len(list_tokens)",
   "id": "1f8ee35d00a409a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157528"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:48:02.258128Z",
     "start_time": "2025-03-01T18:48:02.251270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import numpy as np\n",
    "\n",
    "def label_dataset(sequence, seq_len, batch_size) -> 'TensorDataset':\n",
    "\n",
    "    # n_batches = len(sequence) // batch_size\n",
    "    x, y = [], []\n",
    "\n",
    "    for i in range(0, len(sequence) - seq_len):\n",
    "        split = sequence[i:i+seq_len+1]\n",
    "        \n",
    "        x.append(split[:seq_len])\n",
    "        y.append(split[-1])\n",
    "            \n",
    "    temp_data = TensorDataset(torch.as_tensor(x),\n",
    "                              torch.as_tensor(y))\n",
    "    \n",
    "    return temp_data\n",
    "    # return DataLoader(temp_data, batch_size=batch_size, shuffle=False, drop_last=True)"
   ],
   "id": "2b10fe2d4fa7d4ce",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:49:28.002824Z",
     "start_time": "2025-03-01T18:48:07.607088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "list_datasets = []\n",
    "\n",
    "for sequence in list_tokens:\n",
    "    list_datasets.append(label_dataset(sequence, seq_len=16, batch_size=64))\n",
    "\n",
    "list_datasets = ConcatDataset(list_datasets)\n",
    "train_loader = DataLoader(list_datasets, batch_size=64, shuffle=True, drop_last=True)"
   ],
   "id": "541dcf2109215660",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:49:35.697417Z",
     "start_time": "2025-03-01T18:49:35.690414Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_loader)",
   "id": "2402d4e7cef6d1f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348026"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:49:39.391905Z",
     "start_time": "2025-03-01T18:49:37.627653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "for batch in train_loader:\n",
    "    x, y = batch\n",
    "    print(len(x), y)\n",
    "    break"
   ],
   "id": "9e2a0f6624f35920",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 tensor([ 2069,  2099,  1005,  2002,  1024,  7454,  2096,  9815,  1015, 18944,\n",
      "         2015,  3900,  1996,  2185,  5182,  2009,  1997,  2233,  2095,  2060,\n",
      "         7076,  3455,  2981, 24267,  2822,  2365,  3777,  1998,  5608,  2001,\n",
      "         1997,  3530,  1996,  3813,  1996,  4799,  2011,  2013,  1996,  1055,\n",
      "         2590,  2007,  1055,  6006,  2004,  5546,  2233,  5485,  8529,  1998,\n",
      "         1998,  1996,  1017, 16798,  5307,  4733,  5279, 12350, 11638,  2099,\n",
      "         1057,  2569, 13970, 10812])\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='functions'></a>\n",
    "# functions\n",
    "#### RNN"
   ],
   "id": "c548759c05be0f4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T18:51:46.716404Z",
     "start_time": "2025-03-01T18:51:46.709119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, hidden_dim, num_layers, device):\n",
    "        return (torch.zeros(num_layers, batch_size, hidden_dim).to(device),\n",
    "                torch.zeros(num_layers, batch_size, hidden_dim).to(device))"
   ],
   "id": "4c0b4489e1dcbaab",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### train",
   "id": "7db8c435df1e316e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from time import perf_counter\n",
    "\n",
    "def train_model(model, data_loader, criterion, optimizer, n_epochs, n_layers, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        hidden = model.init_hidden(batch_size, hidden_dim, n_layers, device)\n",
    "        \n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, target = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "            \n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f'Epoch {epoch + 1}/{n_epochs} | Loss: {avg_loss:.4f}')"
   ],
   "id": "99ab8bcb83390fcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vocab_size = len(tokenizer)\n",
    "embed_dim = 128\n",
    "hidden_dim = 256\n",
    "\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "\n",
    "\n",
    "rnn = RNN(vocab_size,\n",
    "          embed_dim=embed_dim,\n",
    "          hidden_dim=hidden_dim,\n",
    "          num_layers=num_layers).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "torch.save(rnn, 'torch-model-v0.3.pt')"
   ],
   "id": "4e9f97e3076a2c81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_model(rnn,\n",
    "            data_loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            n_epochs=n_epochs,\n",
    "            n_layers=num_layers,\n",
    "            device=device)"
   ],
   "id": "198396ae791720cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "35e17fce3e735d4a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
