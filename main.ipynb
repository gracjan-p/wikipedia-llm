{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### setup",
   "id": "8b605a2ac04572b8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:04.928280Z",
     "start_time": "2025-02-27T18:54:01.931809Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "    dev_count = torch.cuda.device_count()\n",
    "    dev_current = torch.cuda.current_device()\n",
    "    dev_name = torch.cuda.get_device_name(dev_current)\n",
    "    print(f'Device count: {dev_count}')\n",
    "    print(f'Current device: {dev_current}')\n",
    "    print(f'Device name: {dev_name}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### data path",
   "id": "5527f9ad7968ad2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:05.098404Z",
     "start_time": "2025-02-27T18:54:04.929286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "data_path = 'D:\\\\data-science\\\\wikipedia\\\\tokens'\n",
    "all_files = os.listdir(data_path)\n",
    "file_path = os.path.join(data_path, all_files[0])\n",
    "\n",
    "data = torch.load(file_path)\n",
    "data.shape"
   ],
   "id": "603f47b1721404d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([157528, 256])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:05.238039Z",
     "start_time": "2025-02-27T18:54:05.100394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# flatten data\n",
    "data = data.view(-1)\n",
    "\n",
    "# remove padding\n",
    "data = data[data != 0]\n",
    "\n",
    "data.shape"
   ],
   "id": "7c25ecc1c68745a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28096187])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:57:17.498085Z",
     "start_time": "2025-02-27T18:57:17.491085Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(data[:100])",
   "id": "8c6fb332e28b16ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] \" the angel of 8th ave. \" ( stylised in all lowercase ) is a song by australian alternative rock band gang of youths, released on 15 june 2021 as the lead single from their second ep, total serene ( 2021 ). the track also features on the band \\' s third studio album, angel in realtime ( 2022 ). frontman david le \\' aupepe said the song was inspired by \" falling in love and finding a new life in a new city together.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:09.701922Z",
     "start_time": "2025-02-27T18:54:05.240036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "id": "6c78bf4ed501dcc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Functions\n",
    "#### 1) labeled_sequences"
   ],
   "id": "ca07ddc7386ca7a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:15.628263Z",
     "start_time": "2025-02-27T18:54:15.621090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def labeled_sequences(words, sequence_length, batch_size):\n",
    "\n",
    "    n_batches = len(words) // batch_size\n",
    "    x, y = [], []\n",
    "    words = words[:n_batches * batch_size]\n",
    "\n",
    "    for i in range(0, len(words)-sequence_length):\n",
    "        i_end = i + sequence_length\n",
    "\n",
    "        # all words excluding last one are X\n",
    "        batch_x = words[i:i_end]\n",
    "        x.append(batch_x)\n",
    "\n",
    "        # last word in sequence is y / label\n",
    "        batch_y = words[i_end]\n",
    "        y.append(batch_y)\n",
    "\n",
    "    dataset = TensorDataset(torch.from_numpy(np.asarray(x)), torch.from_numpy(np.asarray(y)))\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    return data_loader"
   ],
   "id": "73295e520d37daae",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### RNN()",
   "id": "faf26bc7c66565ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:23.297760Z",
     "start_time": "2025-02-27T18:54:23.288690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, emb_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = output_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.to(torch.int64)\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        # stack layers\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # output\n",
    "        out = self.fc(lstm_out)\n",
    "        out = out.view(batch_size, -1, self.output_size)\n",
    "        out = out[:, -1]\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weights = next(self.parameters()).data\n",
    "        hidden = ((weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda()),\n",
    "                  (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda()))\n",
    "        \n",
    "        return hidden"
   ],
   "id": "a07c6f28dbcdbe9e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### forward_back_prop()",
   "id": "75dd4f3d5c13fd42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:24.201479Z",
     "start_time": "2025-02-27T18:54:24.193876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
    "    # creating variables for hidden state to prevent back-propagation\n",
    "    # of historical states\n",
    "    h = tuple([each.data for each in hidden])\n",
    "\n",
    "    rnn.zero_grad()\n",
    "    # move inputs, targets to GPU \n",
    "    inputs, targets = inp.cuda(), target.cuda()\n",
    "\n",
    "    output, h = rnn(inputs, h)\n",
    "\n",
    "    loss = criterion(output, targets)\n",
    "\n",
    "    # perform backpropagation and optimization\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(rnn.parameters(), 5)\n",
    "    optimizer.step()\n",
    "\n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    return loss.item(), h"
   ],
   "id": "f4d3776258135917",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### train_rnn()",
   "id": "f94153a4770a61a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:25.113882Z",
     "start_time": "2025-02-27T18:54:25.106522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import perf_counter\n",
    "import numpy as np\n",
    "\n",
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
    "    \n",
    "    batch_losses = []\n",
    "    rnn.train()\n",
    "\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch {epoch_i} / {n_epochs}\\n\")\n",
    "        \n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "\n",
    "        start = perf_counter()\n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            \n",
    "            # moving inputs and labels to gpu\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # forward and backward propagation\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)\n",
    "            \n",
    "            # loss\n",
    "            batch_losses.append(loss)\n",
    "            \n",
    "            # monitor\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                end = perf_counter()\n",
    "                time = np.round(end - start, 4)\n",
    "                print(f'Batch: {batch_i}  Loss: {np.average(batch_losses)}  Time: {time}s\\n')\n",
    "                batch_losses = []\n",
    "                start = perf_counter()\n",
    "\n",
    "    # Return the trained RNN\n",
    "    return rnn"
   ],
   "id": "d83e92e884de7f5d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### parameters",
   "id": "67e50164680fc9e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:54:27.187296Z",
     "start_time": "2025-02-27T18:54:27.177651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "output_size = vocab_size\n",
    "embedding_dim = 200\n",
    "hidden_dim = 250\n",
    "n_layers = 2\n",
    "batch_size = 64\n",
    "\n",
    "show_every_n_batches = 1_000"
   ],
   "id": "909ce43539e3f40e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_loader = labeled_sequences(words=data[:len(data) // 8], sequence_length=16, batch_size=batch_size)",
   "id": "e30ce0116485c9af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:55:08.172224Z",
     "start_time": "2025-02-27T18:55:07.884869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "rnn.cuda()"
   ],
   "id": "e6a9af99a1e50e17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(30522, 200)\n",
       "  (lstm): LSTM(200, 250, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=250, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
    "\n",
    "model_path = os.path.join('./torch-model-v0.2.pt')\n",
    "torch.save(trained_rnn, model_path)"
   ],
   "id": "42b86eb58c45ff85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:55:13.313990Z",
     "start_time": "2025-02-27T18:55:13.257701Z"
    }
   },
   "cell_type": "code",
   "source": "model_rnn = torch.load('torch-model-v0.2.pt', weights_only=False)",
   "id": "b8fe3dc5bbe932cb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:06:39.769381Z",
     "start_time": "2025-02-27T21:06:39.469599Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained('gpt2')",
   "id": "f81eb2035858f23d",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:29:04.271614Z",
     "start_time": "2025-02-27T22:29:04.051609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create text generation base on the model\n",
    "model_rnn.eval()\n",
    "model_rnn.cuda()\n",
    "\n",
    "hidden = model_rnn.init_hidden(1)\n",
    "\n",
    "input_text = 'test'\n",
    "generated_text = input_text.split()\n",
    "\n",
    "for _ in range(20):\n",
    "    with torch.no_grad():\n",
    "        input_tokens = torch.tensor(tokenizer.encode(input_text, return_tensors='pt')).cuda()\n",
    "        output, hidden = model_rnn(input_tokens, hidden)\n",
    "        predicted_idx = torch.argmax(output[-1]).item()\n",
    "        \n",
    "        predicted_word = tokenizer.decode(predicted_idx, ignore_special_tokens=False)\n",
    "        generated_text.append(predicted_word)\n",
    "        # print(generated_text)\n",
    "        \n",
    "generated_text = ' '.join(generated_text)\n",
    "print(generated_text)"
   ],
   "id": "80b0196613185d3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  Cl  experience attle attle attle attle attle attle attle attle attle attle attle attle attle attle attle attle attle attle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ati\\AppData\\Local\\Temp\\ipykernel_16088\\3487664760.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tokens = torch.tensor(tokenizer.encode(input_text, return_tensors='pt')).cuda()\n"
     ]
    }
   ],
   "execution_count": 86
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
